---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# polychoric <img src="man/figures/logo.png" align="right" height="139" />

<!-- badges: start -->
[![R-CMD-check](https://github.com/Marwolaeth/polychoric/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Marwolaeth/polychoric/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

Fast Polychoric Correlation for Vectors and Data Frames

## Installation

You can install the development version of polychoric from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("Marwolaeth/polychoric")
```

## About
Polychoric is a package that provides a wrapper for C++ routines used to calculate polychoric correlation coefficients, which are often used in social science or marketing research. The single `polycorr()` function can take in ordinal factor vectors, a contingency table, or a data frame and returns corresponding polychoric correlation estimates in the form of a single numeric value or a correlation matrix.

<details>
  <summary>Spoiler</summary>
  
  Pathetic amateurish craftsmanship
  
 </details>
  
## The Purpose
Polychoric correlation coefficients are a type of correlation coefficient used to measure the relationship between two ordinal variables. They are computed by estimating the correlation between two underlying continuous variables that are assumed to give rise to the observed ordinal data. The `polycorr()` function estimates latent Pearson correlation coefficients under the assumption that the latent traits of interest are standard normal random variables.

The computation of polychoric correlation coefficients involves estimating the thresholds (here called `gamma` and `tau`, like in (*Drasgow 1986*), or just `tau` as in `psych` package (*Revelle 2023*)) that separate the ordinal categories for each variable. These thresholds are used to transform the ordinal data into a set of continuous variables, which can then be used to estimate the correlation coefficient using standard methods. The `polycorr()` function currently estimates the thresholds using a two-step maximum likelihood estimation, where first the thresholds are deduced from univariate distributions of ordinal variables and then the `L-BFGS-B` optimization algorithm (implemented in [LBFGS++](https://github.com/yixuan/LBFGSpp/), *Yixuan 2023*) is used to find the value of the correlation coefficient $\rho$ that maximizes the likelihood of the observed contingency table. The `toms462` (*Donnelly 1973*, *Owen 1956*) [algorithm](https://people.sc.fsu.edu/~jburkardt/cpp_src/toms462/toms462.html) is used to approximate the bivariate normal distribution (quadrant probabilities) of threshold values.

Polychoric correlation coefficients are useful for analyzing data that involve ordinal variables, such as Likert scales or survey responses. They provide a measure of the strength and direction of the relationship between two ordinal variables, which can be useful for understanding patterns in the data.

## Example

### Data preview

```{r example-data}
library(polychoric)
library(psych)
if (!require(likert)) {
  install.packages('likert')
  library(likert)
}
data("gss12_values", package = 'polychoric')
head(gss12_values, 13)
```

```{r example-data-plot}
# likert() doesn't work with tibbles
gss12_values |> as.data.frame() |> likert() |> plot()
```

### For a pair of discrete vectors

Coefficient only:

```{r example-xy-coef}
polycorr(gss12_values$valorig, gss12_values$valeql)
```

Full output:

```{r example-xy-full}
polycorr(gss12_values$valorig, gss12_values$valeql, coef.only = FALSE)
```

### For a contingency table

```{r example-contingency}
(G <- table(gss12_values$valorig, gss12_values$valeql))
polycorr(G)
# side with psych:polychoric()
psych::polychoric(G, correct = .1)$rho
```

Notice that threshold values are exactly the same for both functions:

```{r example-contingency-full}
polycorr(G, coef.only = FALSE)
# side with psych:polychoric()
psych::polychoric(G, correct = .1)
```

### For a data frame

```{r example-corrmatrix}
polycorr(gss12_values)
```

Let's visualise and compare our matrices. We suggest `pheatmap` package for quick correlation matrix visualisation. `corrplot` is also a good option.

```{r example-corrmatrix-vis}
#| layout-ncol: 2
#| fig-cap: 
#|   - "psych correlation matrix"
#|   - "polychoric correlation matrix"
if (!require(pheatmap)) {
  install.packages('pheatmap')
  library(pheatmap)
}
rho1 <- polycorr(gss12_values)
# psych::polychoric() doesn't work with factor data directly
gss_num <- gss12_values |> lapply(as.integer) |> as.data.frame()
rho2 <- polychoric(gss_num)
pheatmap(
  rho2$rho,
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  display_numbers = TRUE,
  number_format = '%.2f',
  fontsize_number = 9
)
pheatmap(
  rho1,
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  display_numbers = TRUE,
  number_format = '%.2f',
  fontsize_number = 9
)
```

### Handling mixed variable types

The `polycorr()` function is currently limited in its flexibility as it only provides polychoric estimation for ordinal variables and does not support biserial or polyserial estimation for mixed ordinal and continuous variables. The function does, however, attempt to recognise potentially non-discrete variables, allowing for up to 10 levels, like in [World Values Survey](https://www.worldvaluessurvey.org/wvs.jsp) questionnaire items. In comparison, the `polychoric()` function from the `psych` package allows up to 8 levels by default.

It's worth noting that variables with a high number of distinct values may cause estimation issues, so the `polycorr()` function returns Spearman's $\rho$ instead (with a warning).

```{r example-mixed}
x <- rnorm(nrow(gss12_values))
polycorr(gss12_values$valspl, x)
```

### Handling missing values

The `polycorr()` function always uses pairwise complete observations. Therefore, the user need not worry about missing data. However, depending on the analysis design and the ratio of missing data, it may be essential to check for patterns of missingness and consider imputation.

The General Social Survey Schwartz Values Module dataset is cleared of missing values (non-response or non-applicable). Here we introduce some NAs into random places across the dataset. The summary will show the dataset now actually contains missings.

```{r example-missing-01}
gss_miss <- gss12_values
mask <- matrix(
  sample(
    c(TRUE, FALSE),
    nrow(gss_miss)*ncol(gss_miss),
    replace = TRUE,
    prob = c(.9, .1)
  ),
  nrow = nrow(gss_miss)
)
gss_miss[!mask] <- NA
summary(gss_miss)
```

Let's rerun the estimation: the function works, though coefficients may be different.

```{r example-missing-02}
pheatmap(
  polycorr(gss_miss),
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  display_numbers = TRUE,
  number_format = '%.2f',
  fontsize_number = 9
)
```

## Performance

Probably the only reason the `polychoric` package may be useful is that it is fast. During alpha-testing of the source code, it was nearly 50x faster in creating a correlation matrix than the gold standard `psych::polychoric()`. The package version is 5 times slower than the raw source code. However, `polychoric` still introduces a significant improvement in performance and can save a market researcher a couple of minutes a day.

```{r benchmark}
if (!require(microbenchmark)) {
  install.packages('microbenchmark')
  library(microbenchmark)
}
bm <- microbenchmark(
  standard = polychoric(gss_num),
  polycorr = polycorr(gss12_values),
  times = 32L,
  control = list(warmup = 6)
)
bm
```

## Development
This is an alpha version of the package. It is under development.

Please report any issues you came up with on the [issues](https://github.com/Marwolaeth/polychoric/issues) page.

<details>
  <summary>The upcoming steps</summary>
  
  1. Optimise `Polychoric` class in the source code.
  2. Provide a polyserial correlation estimation function.
  3. Implement (optional) more robust distributional assumptions, e.g. a skew normal distribution (*Jin and Yang-Wallentin 2017*).
 </details>

## References
1. Drasgow, Fritz (1986). Polychoric and polyserial correlations. The Encyclopedia of Statistics. 7. 68-74.

2. Revelle, William (2023). _psych: Procedures for Psychological, Psychometric, and Personality Research_. Northwestern University, Evanston, Illinois. R package version 2.3.3, <https://CRAN.R-project.org/package=psych>.

3. Olsson, Ulf (1979). Maximum Likelihood Estimation of the Polychoric Correlation Coefficient, Psychometrika, 44:443-460.

4. Donnelly, Thomas (1973). Algorithm 462: Bivariate Normal Distribution, Communications of the ACM, October 1973, Volume 16, Number 10, page 638.

5. Owen, Donald (1956). Tables for Computing Bivariate Normal Probabilities, Annals of Mathematical Statistics, December 1956, Volume 27, Number 4, pages 1075-1090.

6. Qiu, Yixuan (2023). LBFGS++: A Header-only C++ Library for L-BFGS and L-BFGS-B Algorithms. Available at: https://lbfgspp.statr.me/

7. Jin S, Yang-Wallentin F (2017). Asymptotic Robustness Study of the Polychoric Correlation Estimation. Psychometrika. 2017 Mar;82(1):67-85.
